#              nmax=40
#               )
gs_lcode = gstat(id="SM", formula=(Lcode=="SM")~1, locations = ~X+Y,
data=ds,
model=vgt_SM, nmax=60) %>%
gstat(id="FZ", formula=(Lcode=="FZ")~1, locations = ~X+Y,
data=ds,
model=vgt_SM,nmax=60) %>%
gstat(id="UM", formula=(Lcode=="UM")~1, locations = ~X+Y,
data=ds,
model=vgt_SM,nmax=60) %>%
gstat(id="SA", formula=(Lcode=="SA")~1, locations = ~X+Y,
data=ds,
model=vgt_SM,nmax=60)
vg_lcode = variogram(gs_lcode, cutoff=225)
gs_lcode =gstat::fit.lmc(v=vg_lcode, model = vgm_SM,
g = gs_lcode, correct.diagonal = 1.001) # correct.diagonal needed to force positive-definiteness
#plot variograms
plot(vg_lcode, model=gs_lcode$model)
# cockriging
cokr_all = predict(gs_lcode, newdata=xy_grid, debug.level = -1)#,indicators=T
# plot the results
a =ggplot(cokr_all, aes(X, Y))+
geom_raster(aes(fill=SM.pred))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "roma")+ggtitle("SM")
b =ggplot(cokr_all, aes(X, Y))+
geom_raster(aes(fill=FZ.pred))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "roma")+ggtitle("FZ")
c =ggplot(cokr_all, aes(X, Y))+
geom_raster(aes(fill=UM.pred))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "roma")+ggtitle("UM")
d =ggplot(cokr_all, aes(X, Y))+
geom_raster(aes(fill=SA.pred))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "roma")+ggtitle("SA")
gridExtra::grid.arrange(a,b,c,d,nrow=2, ncol=2)
#simulation for Lcodes
#simlcodes = predict(gs_lcode, newdata=xy_grid, debug.level = -1,nsim=100)
# WE use indicators
simlcodes = predict(gs_lcode, newdata=xy_grid, debug.level = -1,indicators=T,nsim=100)
library("manipulate")
all_lcode_simulationplot = function(i,sim_ds){
a=ggplot()+
geom_raster(data=sim_ds,aes( x=X, y=Y,fill=sim_ds[,2+i]))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "bilbao")+
ggtitle(paste(sep="",i," Realisation of SM " ))
b=ggplot()+
geom_raster(data=sim_ds ,aes( x=X, y=Y,fill=sim_ds[,2+i+100]))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "vik")+
ggtitle(paste(sep="",i," Realisation of FZ " ))
c=ggplot()+
geom_raster(data=sim_ds,aes( x=X, y=Y,fill=sim_ds[,2+i+200]))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "lajolla")+
ggtitle(paste(sep="",i," Realisation of  UM" ))
d=ggplot()+
geom_raster(data=sim_ds,aes(x=X, y=Y,fill=sim_ds[,2+i+300]))+
coord_fixed()+
theme_classic()+
scico::scale_fill_scico(palette = "bilbao")+
ggtitle(paste(sep="",i," Realisation of SA " ))
gridExtra::grid.arrange(a, b,c,d,nrow=2,ncol=2) #set the number of plots
}
manipulate(all_lcode_simulationplot(i,simlcodes), i=slider(1,100))
save.image("U:/STUDY/blockkurs/2022/Ibadullaev/fu.RData")
save.image("U:/STUDY/blockkurs/2022/Ibadullaev/fu.RData")
save.image("U:/STUDY/blockkurs/2022/Ibadullaev/fu.RData")
## Lcode + Co
(mat = matrix(c(1,2,1,3), ncol=2))
layout(mat, height=c(2,3))  # alternative to par(mfrow=...)
(lvl = abbreviate(levels(ds$Lcode))) # useful later
# rock type vs logCo
plot(log(Co)~Lcode, data=ds, border=1:5)
## Apparently, Co is lowest in FZ, lower in UM,
#  average in SM  and highest in
#  SA. There is a dependence between CO and lithology!
#  Given these results +  low number of data in Portlandian:
#convert categorical values to integers
ds$lithcode =
ds$Lcode %>% # take the original Lcode
as.integer %>%   # convert the categories to integers (==position in the lvl vector)
factor(labels=c("FZ", "SA", "SM", "UM"))
# check the operation was well done
summary(ds$lithcode)
table(ds$lithcode, ds$Lcode)
contrasts(ds$lithcode) <- contr.treatment(levels(ds$lithcode), base=2)
# check the effect: (if necessary, read ?contr.treatment)
ds$lithcode
contr.treatment(levels(ds$lithcode), base=2) %>%
{lm(log(Co)~lithcode, data=ds, contrasts=.)} %>% summary
## multivariate model for Co and lcode together
gs_Co4lcodes = gstat(id="Co", formula=log(Co)~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="FZ", formula=(lithcode=="FZ")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="SA", formula=(lithcode=="SA")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="UM", formula=(lithcode=="UM")~1, locations = ~X+Y,
data=ds, nmax=50)
par(mfrow=c(1,1))
# empirical variogram
vg_Co4lcodes = variogram(gs_Co4lcodes, cutoff=225)
plot(vg_Co4lcodes)
# variogram model
# let's start with the model for Ni, without nugget
# adding the wave model of Tuesday
vgt = vgm(model="Sph", range=100,nugget = 0.2 ,psill=0.05)
# you can also try switching in and out some of the components and slightly move ranges
gs_Co4lcodes = gstat::fit.lmc(v=vg_Co4lcodes, model=vgt, g=gs_Co4lcodes, correct.diagonal = 1.0001)
plot(vg_Co4lcodes, model=gs_Co4lcodes$model)
# vectors of x and y coordinates of the grid nodes,
#   covering the range of the data, and with a step
#   allowing for interpolation between data
par(mfrow=c(1,1))
plot(Y~X, data=ds, asp=1)
xx = seq(from=rangesXY[1,"X"], to=rangesXY[2,"X"],by=10, length.out = length(ds$X))
## multivariate model for Co and lcode together
gs_Co4lcodes = gstat(id="Co", formula=log(Co)~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="FZ", formula=(lithcode=="FZ")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="SA", formula=(lithcode=="SA")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="UM", formula=(lithcode=="UM")~1, locations = ~X+Y,
data=ds, nmax=50)
par(mfrow=c(1,1))
# empirical variogram
vg_Co4lcodes = variogram(gs_Co4lcodes, cutoff=225)
plot(vg_Co4lcodes)
# variogram model
# let's start with the model for Ni, without nugget
# adding the wave model of Tuesday
vgt = vgm(model="Sph", range=100,nugget = 0.2 ,psill=0.05)
# you can also try switching in and out some of the components and slightly move ranges
gs_Co4lcodes = gstat::fit.lmc(v=vg_Co4lcodes, model=vgt, g=gs_Co4lcodes, correct.diagonal = 1.0001)
plot(vg_Co4lcodes, model=gs_Co4lcodes$model)
# vectors of x and y coordinates of the grid nodes,
#   covering the range of the data, and with a step
#   allowing for interpolation between data
par(mfrow=c(1,1))
plot(Y~X, data=ds, asp=1)
xx = seq(from=rangesXY[1,"X"], to=rangesXY[2,"X"], length.out = length(ds$X))
yy = seq(from=rangesXY[1,"Y"], to=rangesXY[2,"Y"], length.out = length(ds$X))
# 4 points
# grid definition must be the same in gs object Easting=x, Northing=y
xxyy_grid = expand.grid(X=xx, Y=yy)
points(xxyy_grid,col=2,pch=".")
xv_Co4lcodes = gstat.cv(gs_Co4lcodes)
## multivariate model for Co and lcode together
gs_Co4lcodes = gstat(id="Co", formula=log(Co)~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="FZ", formula=(lithcode=="FZ")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="SA", formula=(lithcode=="SA")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="UM", formula=(lithcode=="UM")~1, locations = ~X+Y,
data=ds, nmax=50)
par(mfrow=c(1,1))
# empirical variogram
vg_Co4lcodes = variogram(gs_Co4lcodes, cutoff=225)
plot(vg_Co4lcodes)
# variogram model
# let's start with the model for Ni, without nugget
# adding the wave model of Tuesday
vgt = vgm(model="Sph", range=100,nugget = 0.2 ,psill=0.05)
# you can also try switching in and out some of the components and slightly move ranges
gs_Co4lcodes = gstat::fit.lmc(v=vg_Co4lcodes, model=vgt, g=gs_Co4lcodes, correct.diagonal = 1.0001)
plot(vg_Co4lcodes, model=gs_Co4lcodes$model)
# vectors of x and y coordinates of the grid nodes,
#   covering the range of the data, and with a step
#   allowing for interpolation between data
par(mfrow=c(1,1))
plot(Y~X, data=ds, asp=1)
xx = seq(from=rangesXY[1,"X"], to=rangesXY[2,"X"], length.out = length(ds$X))
yy = seq(from=rangesXY[1,"Y"], to=rangesXY[2,"Y"], length.out = length(ds$X))
# 4 points
# grid definition must be the same in gs object Easting=x, Northing=y
xxyy_grid = expand.grid(X=xx, Y=yy)
points(xxyy_grid,col=2,pch=".")
xv_Co4lcodes = gstat.cv(gs_Co4lcodes)
# cokriging
cok_Co4lcodes = predict(gs_Co4lcodes, newdata=xxyy_grid, debug.level = -1)
myplot = function(x, variable, breaks=10, colorscale=RColorBrewer::brewer.pal(11, "Spectral")){
# allow for giving specific breaks or the desired number of breaks
if(length(breaks)==1){
breaks = pretty(x[,variable], n = breaks)
}
# ensure that the color scale has always one color less than breaks
if(length(breaks)-length(colorscale)!=1){
colorscale = colorRampPalette(colorscale)(length(breaks)-1)
}
# plot
cols = colorscale[cut(as.numeric(x[,variable]), breaks = breaks)]
plot(Y~X, data=x, bg=cols, col=NA, asp=1, pch=22)
invisible(list(breaks=breaks, color=colorscale)) # return invisibly the elements of the legend
}
par(mfrow=c(3,3))
#1
myplot(cok_Co4lcodes, variable = "Co.pred");
title("Co.pred")
#2
myplot(cok_Co4lcodes, variable = "FZ.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("FZ.pred")
myplot(cok_Co4lcodes, variable = "SA.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("SA.pred")
myplot(cok_Co4lcodes, variable = "UM.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("UM.pred")
#red is negative or zero, orange 0 and 0.25, yellow transition zone, blue , 1 and 2 dark blue-the highest prob
#3
cok_Co4lcodes$SM.pred = 1 -cok_Co4lcodes$FZ.pred -cok_Co4lcodes$SA.pred-cok_Co4lcodes$UM.pred
myplot(cok_Co4lcodes, variable = "SM.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("SM.pred")
#4
mostProb=cok_Co4lcodes[,c(5,7,9,17)] %>% apply(1, which.max)
cok_Co4lcodes$Lcode.pred =mostProb
myplot(cok_Co4lcodes, variable = "Lcode.pred",breaks =c(0,1.5,2.5,3.5,4.5),col=1:4);
title("The most probable")
myplot(ds, variable = "Lcode",breaks =c(0,1.5,2.5,3.5,4.5),col=1:4);
title("The truth")
# for Ni
## multivariate model for Ni and lcodes together
gs_Ni4lcodes = gstat(id="Ni", formula=log(Ni)~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="FZ", formula=(lithcode=="FZ")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="SA", formula=(lithcode=="SA")~1, locations = ~X+Y,
data=ds, nmax=50) %>%
gstat(id="UM", formula=(lithcode=="UM")~1, locations = ~X+Y,
data=ds, nmax=50)
par(mfrow=c(1,1))
# empirical variogram
vg_Ni4lcodes = variogram(gs_Ni4lcodes, cutoff=225)
plot(vg_Ni4lcodes)
# variogram model
# let's start with the model for Ni, without nugget
# adding the wave model of Tuesday
vgt = vgm(model="Sph", range=100,nugget = 0.2 ,psill=0.05)
# you can also try switching in and out some of the components and slightly move ranges
gs_Ni4lcodes = gstat::fit.lmc(v=vg_Ni4lcodes, model=vgt, g=gs_Ni4lcodes, correct.diagonal = 1.0001)
plot(vg_Ni4lcodes, model=gs_Ni4lcodes$model)
# vectors of x and y coordinates of the grid nodes,
#   covering the range of the data, and with a step
#   allowing for interpolation between data
par(mfrow=c(1,1))
plot(Y~X, data=ds, asp=1)
xx = seq(from=rangesXY[1,"X"], to=rangesXY[2,"X"], length.out = length(ds$X))
yy = seq(from=rangesXY[1,"Y"], to=rangesXY[2,"Y"], length.out = length(ds$X))
# 4 points
# grid definition must be the same in gs object Easting=x, Northing=y
xxyy_grid = expand.grid(X=xx, Y=yy)
points(xxyy_grid,col=2,pch=".")
xv_Ni4lcodes = gstat.cv(gs_Ni4lcodes)
# cokriging
cok_Ni4lcodes = predict(gs_Ni4lcodes, newdata=xxyy_grid, debug.level = -1)
myplot = function(x, variable, breaks=10, colorscale=RColorBrewer::brewer.pal(11, "Spectral")){
# allow for giving specific breaks or the desired number of breaks
if(length(breaks)==1){
breaks = pretty(x[,variable], n = breaks)
}
# ensure that the color scale has always one color less than breaks
if(length(breaks)-length(colorscale)!=1){
colorscale = colorRampPalette(colorscale)(length(breaks)-1)
}
# plot
cols = colorscale[cut(as.numeric(x[,variable]), breaks = breaks)]
plot(Y~X, data=x, bg=cols, col=NA, asp=1, pch=22)
invisible(list(breaks=breaks, color=colorscale)) # return invisibly the elements of the legend
}
par(mfrow=c(3,3))
#1
myplot(cok_Ni4lcodes, variable = "Ni.pred");
title("Ni.pred")
#2
myplot(cok_Ni4lcodes, variable = "FZ.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("FZ.pred")
myplot(cok_Ni4lcodes, variable = "SA.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("SA.pred")
myplot(cok_Ni4lcodes, variable = "UM.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("UM.pred")
#red is negative or zero, orange 0 and 0.25, yellow transition zone, blue , 1 and 2 dark blue-the highest prob
#3
cok_Ni4lcodes$SM.pred = 1 -cok_Ni4lcodes$FZ.pred -cok_Ni4lcodes$SA.pred-cok_Ni4lcodes$UM.pred
myplot(cok_Ni4lcodes, variable = "SM.pred",breaks =c(-2,0,0.25,0.5,1,2));
title("SM.pred")
#4
mostProb=cok_Ni4lcodes[,c(5,7,9,17)] %>% apply(1, which.max)
cok_Ni4lcodes$Lcode.pred =mostProb
myplot(cok_Ni4lcodes, variable = "Lcode.pred",breaks =c(0,1.5,2.5,3.5,4.5),col=1:4);
title("The most probable")
myplot(ds, variable = "Lcode",breaks =c(0,1.5,2.5,3.5,4.5),col=1:4);
title("The truth")
legend("bottomright",legend = levels(ds$Lcode), col = 1:4)
save.image("U:/STUDY/blockkurs/2022/Ibadullaev/fu.RData")
ds = read.csv("Ibadullaev.csv",stringsAsFactors = T) # load data
colnames(ds) # check cols
ds = ds[,-1] # clip 1st col
colnames(ds) # check cols
ds = read.csv("Ibadullaev.csv",stringsAsFactors = T) # load data
colnames(ds) # check cols
ds = ds[,-1] # clip 1st col
colnames(ds) # check cols
# Import Packages
library("gstat")
library("RColorBrewer")
library("magrittr")
library("ggplot2")
library("manipulate")
library("sp")
library("scico")
library("dplyr")
library("gmGeostats")
library("knitr")
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path)) # Set active directory
getwd()
```{r showsimlcodes}
all_lcode_simulationplot(i=30,simlcodes)
allsimulationplot(15,cosim_l,n=20)
allsimulationplot(15,cosim_l,n=20)
#manipulate(simulationplot(i,sim_Co,varname="Co"), i=slider(1,100))
simulationplot(i=30,sim_Co,varname="Co")
#manipulate(simulationplot(i,sim_Ni,varname="Ni"), i=slider(1,100))
simulationplot(i=25,sim_Ni,varname="Ni")
# load data
setwd(dirname(getActiveDocumentContext()$path))
getwd()
raslist = list.files(getwd(),pattern="img$", full.names = T)
rasVars = stack(raslist)
rasVars
#visualize bands
plot(rasVars)
# training data
ta_data = readOGR(getwd(), "TA_1984")
summary(ta_data)
library(sp)
library(rgdal)
library(raster)
library(reshape)
library(grid)
library(gridExtra)
library(RStoolbox)
library(caret)
library(rasterVis)
library(corrplot)
library(doParallel)
library(NeuralNetTools)
library(rstudioapi)
library(ggplot2)
library(e1071)
# load data
setwd(dirname(getActiveDocumentContext()$path))
getwd()
raslist = list.files(getwd(),pattern="img$", full.names = T)
rasVars = stack(raslist)
rasVars
#visualize bands
plot(rasVars)
# training data
ta_data = readOGR(getwd(), "TA_1984")
summary(ta_data)
# Use training points to extract reflectance values
# Next, assign raster values to the training data set.
ta = as.data.frame(extract(rasVars, ta_data))
ta_data@data=data.frame(ta_data@data,ta[match(rownames(ta_data@data),
rownames(ta)),])
#check str
str(ta_data@data)
#check NAs
complete.cases(ta_data@data)
length(ta_data@data[is.na(ta_data@data)])
dim(ta_data@data)
ta_data@data = na.omit(ta_data@data)
length(ta_data@data[is.na(ta_data@data)])
complete.cases(ta_data@data)
dim(ta_data@data)
# Prepare training and test data sets-------
hre_seed = 27
set.seed(hre_seed)
# split data sets
inTraining =createDataPartition(ta_data@data$Cl1984,
p=.80, list=F)
training = ta_data@data[inTraining,]
testing = ta_data@data[-inTraining,]
#check dimensions
dim(training)
dim(testing)
#correlation matrix
bandCorrelations = cor(training[,2:43])
dim(bandCorrelations)
# correlation
corrplot(bandCorrelations, method = "color",
order = 'hclust')
# cutoff with 0.8
highCorrelated = findCorrelation(bandCorrelations,
cutoff = 0.8)
length(highCorrelated)
# names of high correlated variables
names(training)[highCorrelated]
# set-up model tuning parameters
hre_seed=27
set.seed(hre_seed)
fitControl = trainControl(method = "repeatedcv",
number = 5,
repeats = 5)
cl = makePSOCKcluster(5)
registerDoParallel(cl)
timeStart = proc.time()
#remove high correlated data
svm_model = caret::train(factor(Cl1984)~.,data = training[-highCorrelated],
method="svmRadial",
trControl = fitControl,
preProc = c("center","scale"),
tuneLength=3)
proc.time() - timeStart
stopCluster(cl)
print(svm_model)
plot(svm_model)
#check the best model
svm_model$finalModel
pred_svm = predict(svm_model, newdata=testing)
confusionMatrix(data=pred_svm, factor(testing$Cl1984))
# check importance of variables
svm_varImp =varImp(svm_model, competes = FALSE)
library(knitr)
library(kableExtra)
kable(confusionMatrix(data=pred_svm, factor(testing$Cl1984)))
svm_confmatr =confusionMatrix(data=pred_svm, factor(testing$Cl1984))
svm_confmatr %>% kable()
svm_confmatr %>% table()
svm_confmatr %>% as.data.frame()
svm_confmatr %>% plot()
library(yardstick)
autoplot(svm_confmatr, type = "heatmap") +
scale_fill_gradient(low="#D6EAF8",high = "#2E86C1")
svm_confmatr =confusionMatrix(data=pred_svm, factor(testing$Cl1984)) %>% data.frame()
conf_mat(truth_predicted, obs, pred_svm)
conf_mat(factor(testing$Cl1984), testing, pred_svm)
conf_mat(testing$Cl1984, testing, pred_svm)
conf_mat( pred_svm, testing,factor(testing$Cl1984))
conf_mat( pred_svm, testing,factor(testing$Cl1984))
svm_confmatr = confusionMatrix(data=pred_svm, factor(testing$Cl1984))
svm_confmatr
svm_confmatr
autoplot(svm_confmatr, type = "heatmap") +
scale_fill_gradient(low="#D6EAF8",high = "#2E86C1")
#KNN -------------
cl = makePSOCKcluster(5)
registerDoParallel(cl)
set.seed(hre_seed)
training$Cl1984=factor(training$Cl1984)
knn_model =train(Cl1984~., data=training,
method="kknn",
preProcess=c("center","scale"),
trControl=fitControl)
proc.time() - timeStart
stopCluster(cl)
plot(knn_model)
knn_model$finalModel
# display variable importance using the varImp() function
knn_varImp = caret::varImp(knn_model, competes=F)
plot(knn_varImp)
# now let's predict
predKnn = predict(knn_model,newdata=testing)
confusionMatrix(data=predKnn, factor(testing$Cl1984) )
knn_matr=confusionMatrix(data=predKnn, factor(testing$Cl1984) )
#PREDICT
timeStart =proc.time()
cl = makePSOCKcluster(5)
registerDoParallel(cl)
LC_knn <-predict(rasVars,knn_model)
LC_svm <-predict(rasVars,svm_model)
proc.time() - timeStart
stopCluster(cl)
LC_svm_plot <- gplot(LC_svm) + geom_raster(aes(fill= factor(value, labels=c("Agriculture", "Bareland","Green Spaces", "Urban", "Water")))) +scale_fill_manual(values = c("yellow", "grey", "green3", "red", "blue3"),na.translate = F,name= "Land Cover") +
ggtitle("Support Vector Machine Classification") +
theme(plot.title = element_text(lineheight=.4, face="bold")) + coord_equal()
LC_svm_plot
ggsave(plot=LC_svm_plot, "LC_svm_plot.tiff", device = "tiff")
LC_knn_plot <- gplot(LC_knn) + geom_raster(aes(fill = factor(value, labels=c("Agriculture", "Bareland", "Green Spaces", "Urban", "Water")))) + scale_fill_manual(values = c("yellow", "grey", "green3", "red", "blue3"),na.translate = F, name= "Land Cover") + ggtitle("K Nearest Neighbour Classification") +
theme(plot.title = element_text(lineheight=.4, face="bold")) + coord_equal()
LC_knn_plot
ggsave(plot=LC_knn_plot, "LC_knn_plot.tiff", device = "tiff")
grid.arrange(LC_knn_plot, LC_svm_plot, ncol=2)
grid.arrange(LC_knn_plot, LC_svm_plot,LC_84_Multdate, ncol=2)
knn_matr=confusionMatrix(data=predKnn, factor(testing$Cl1984) )
LC_svm_plot <- gplot(LC_svm) + geom_raster(aes(fill= factor(value, labels=c("Agriculture", "Bareland","Green Spaces", "Urban", "Water")))) +scale_fill_manual(values = c("yellow", "grey", "green3", "red", "blue3"),na.translate = F,name= "Land Cover") +
ggtitle("Support Vector Machine Classification") +
theme(plot.title = element_text(lineheight=.4, face="bold")) + coord_equal()
LC_svm_plot
ggsave(plot=LC_svm_plot, "LC_svm_plot.tiff", device = "tiff")
LC_knn_plot <- gplot(LC_knn) + geom_raster(aes(fill = factor(value, labels=c("Agriculture", "Bareland", "Green Spaces", "Urban", "Water")))) + scale_fill_manual(values = c("yellow", "grey", "green3", "red", "blue3"),na.translate = F, name= "Land Cover") + ggtitle("K Nearest Neighbour Classification") +
theme(plot.title = element_text(lineheight=.4, face="bold")) + coord_equal()
LC_knn_plot
ggsave(plot=LC_knn_plot, "LC_knn_plot.tiff", device = "tiff")
grid.arrange(LC_knn_plot, LC_svm_plot,LC_84_Multdate, ncol=2)
View(a)
svm_confmatr
knn_matr
#MULTIDATA CLASSIFICATION
rm(list=ls())
